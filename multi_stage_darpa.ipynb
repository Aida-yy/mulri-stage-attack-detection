{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multi_stage_0821_darpa.ipynb","provenance":[],"collapsed_sections":["S4R6gYQY2PEE","iHXoX5PVkrSz"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"165px"},"toc_section_display":true,"toc_window_display":true}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"D4VxMTdvVcjM","colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"status":"ok","timestamp":1598003966511,"user_tz":-480,"elapsed":8272,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"9221c933-9f9c-4994-f0c3-6e316441fd9c"},"source":["!pip install hmmlearn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hmmlearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7b/33f629a443a0671161c019e55c3f1b511c7e9fdce5ab8c8c3c33470eb939/hmmlearn-0.2.3-cp36-cp36m-manylinux1_x86_64.whl (363kB)\n","\u001b[K     |████████████████████████████████| 368kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n","Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.16.0)\n","Installing collected packages: hmmlearn\n","Successfully installed hmmlearn-0.2.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GE66wrDN4UYy","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1598110470088,"user_tz":-480,"elapsed":52263,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"ed1367f0-96b8-493b-cc14-83faf9fb4238"},"source":["# 挂载google云盘\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ty3sIaMU4R4b","colab":{},"executionInfo":{"status":"ok","timestamp":1598146840768,"user_tz":-480,"elapsed":7282,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","import tensorflow as tf\n","import csv\n","from datetime import datetime\n","import time\n","import random\n","\n","from sklearn.model_selection import train_test_split\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P48DM2okBr9Z","colab_type":"text"},"source":["### preprocessing"]},{"cell_type":"code","metadata":{"id":"pmE31tNvj5Gf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598146840771,"user_tz":-480,"elapsed":6525,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["#load data\n","def dataLoader(input_file):\n","    data = pd.read_csv(input_file)\n","    alerts = data.event\n","    labels = data.stage\n","    return alerts.tolist(), labels.tolist()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDkKKsrmBr9d","colab_type":"text"},"source":["#### metrics"]},{"cell_type":"code","metadata":{"id":"e9w-4PgtBr9d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598146840772,"user_tz":-480,"elapsed":5930,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["def eva_metrics1(y_true,y_pred,stages,hmm=False):\n","    pre,rec = [],[]\n","    for t,p in zip(y_true,y_pred):\n","        if hmm:\n","            t = [t[0]]+[t[i] for i in range(1,len(t)) if t[i] != t[i-1]]\n","            p = [p[0]]+[p[i] for i in range(1,len(p)) if p[i] != p[i-1]]\n","        num_correct = len([i for i,j in zip(t,p) if i==j])\n","        num_true = len(t)\n","        num_pre = len(p)\n","        pre.append(num_correct / (num_pre))\n","        rec.append(num_correct / (num_true))\n","    precision = sum(pre)/len(pre)\n","    recall = sum(rec)/len(rec)\n","    f1 = 2*precision*recall/(precision+recall)    \n","    print(\"precison: \", precision)\n","    print(\"recall: \", recall)\n","    print(\"f1: \", f1)\n","    return precision,recall,f1\n","\n","def eva_metrics2(y_true,y_pred,stages):\n","    pre,rec = [],[]\n","    for t,p in zip(y_true,y_pred):\n","        #正样本\n","        if all([stages[i] in t for i in range(len(stages))]):\n","            num_correct = len([i for i,j in zip(t,p) if i==j and i!='o'])\n","            num_true = len([i for i in t if i!='o'])\n","            num_pre = len([i for i in p if i!=\"o\"])\n","            pre.append(num_correct / (num_pre))\n","            rec.append(num_correct / (num_true))\n","        else:#负样本\n","            num_correct = len([i for i,j in zip(t,p) if i==j and i=='o'])\n","            num_true = len([i for i in t if i=='o'])\n","            num_pre = len([i for i in p if i=='o'])\n","            pre.append(num_correct / (num_pre))\n","            rec.append(num_correct / (num_true))\n","    precision = sum(pre)/len(pre)\n","    recall = sum(rec)/len(rec)\n","    f1 = 2*precision*recall/(precision+recall)    \n","    print(\"precison: \", precision)\n","    print(\"recall: \", recall)\n","    print(\"f1: \", f1)\n","    return precision,recall,f1\n","\n","def eva_metrics5(y_true,y_pred,stages,hmm = False):\n","    tp,fp,fn,tn = 0,0,0,0\n","    for t,p in zip(y_true,y_pred):\n","        if hmm:\n","            t = [t[0]]+[t[i] for i in range(1,len(t)) if t[i] != t[i-1]]\n","            p = [p[0]]+[p[i] for i in range(1,len(p)) if p[i] != p[i-1]]\n","        #正样本\n","        if all([stages[i] in t for i in range(len(stages))]):\n","            if t == p:\n","                tp += 1\n","            else:\n","                fn += 1\n","        #负样本\n","        else:\n","            if t == p:\n","                tn += 1\n","            else:\n","                fp += 1\n","    if tp == 0 and fp == 0:\n","        return 0,0,0\n","    precision = tp/(tp+fp)\n","    recall = tp/(tp+fn)\n","    f1 = 2*precision*recall/(precision+recall)    \n","    print(\"precison: \", precision)\n","    print(\"recall: \", recall)\n","    print(\"f1: \", f1)\n","    return precision,recall,f1"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4Mola8BBr9k","colab_type":"text"},"source":["#### stage data"]},{"cell_type":"code","metadata":{"id":"61hbhC-nBr9l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598146842095,"user_tz":-480,"elapsed":6506,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["def generate_2_samples(s1,s2,other,label,length,numbers,k):\n","    \"\"\"\n","    随机采样正样本，负样本（长度随机、采样随机）\n","    numbers: 样本个数\n","    k：负样本比例,负样本 k*numbers\n","    \"\"\"\n","    px,py,phmm_y = [],[],[]\n","    nx,ny,nhmm_y = [],[],[]\n","\n","    for i in range(numbers):\n","        # length = random.randint(int(pow(length,0.5)),length) #int(random.random()*length) if int(random.random()*length) >= 1 else 1\n","        k1 = int(random.random()*len(s1)) if int(random.random()*len(s1))>= 1 else 1\n","        k2 = int(random.random()*len(s2)) if int(random.random()*len(s2))>= 1 else 1\n","        r1 = [s1[i] for i in sorted(random.choices(range(len(s1)),k=k1))]\n","        r2 = [s2[i] for i in sorted(random.choices(range(len(s2)),k=k2))]        \n","        p1 = random.randint(int(length*0.5),length)\n","        p2 = random.randint(int(length*0.5),length)\n","        px.append([other[i] for i in sorted(random.choices(range(len(other)),k = p1))]+\n","                  r1+\n","                  [other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r2 + \n","                  [other[i] for i in sorted(random.choices(range(len(other)),k = p2))])\n","\n","        py.append([\"sos\",\"s1\",\"s2\",\"eos\"])\n","        phmm_y.append([\"o\"]*p1+\n","                      [\"s1\"]*len(r1)+\n","                      [\"o\"]*length+\n","                      [\"s2\"]*len(r2)+\n","                      [\"o\"]*p2)\n","        \n","        if i % k == 0:\n","            nx.append(random.choices(other,k = length+p1+p2+len(r1)+len(r2)))\n","            ny.append([\"sos\",\"o\",\"eos\"])\n","            nhmm_y.append([\"o\"]*(length+p1+p2++len(r1)+len(r2)))\n","    x,y,hmm_y = px+nx,py+ny,phmm_y+nhmm_y\n","    return x,y,hmm_y\n","\n","\n","def generate_3_samples(s1,s2,s3,other,label,length,numbers,k=1):\n","    \"\"\"\n","    numbers: 样本个数\n","    k：负样本比例\n","    \"\"\"\n","    px,py,phmm_y = [],[],[]\n","    nx,ny,nhmm_y = [],[],[]\n","    for i in range(numbers):\n","        k1 = int(random.random()*len(s1)) if int(random.random()*len(s1))>= 1 else 1\n","        k2 = int(random.random()*len(s2)) if int(random.random()*len(s2))>= 1 else 1\n","        k3 = int(random.random()*len(s3)) if int(random.random()*len(s3))>= 1 else 1\n","        r1 = [s1[i] for i in sorted(random.choices(range(len(s1)),k=k1))]\n","        r2 = [s2[i] for i in sorted(random.choices(range(len(s2)),k=k2))]\n","        r3 = [s3[i] for i in sorted(random.choices(range(len(s3)),k=k3))]    \n","        p1 = random.randint(int(length*0.5),length)\n","        p2 = random.randint(int(length*0.5),length)\n","        px.append([other[i] for i in sorted(random.choices(range(len(other)),k = p1))]+\n","                  r1+\n","                  [other[i] for i in sorted(random.choices(range(len(other)),k = length))] + \n","                  r2 +\n","                  [other[i] for i in sorted(random.choices(range(len(other)),k = length))] +\n","                  r3+\n","                  [other[i] for i in sorted(random.choices(range(len(other)),k = p2))])\n","        py.append([\"sos\",\"s1\",\"s2\",\"s3\",\"eos\"])\n","        phmm_y.append([\"o\"]*p1+[\"s1\"]*len(r1)+\n","                      [\"o\"]*length+[\"s2\"]*len(r2)+\n","                      [\"o\"]*length+[\"s3\"]*len(r3)+[\"o\"]*p2)\n","        if i%k == 0:\n","            nx.append(random.choices(other,k = p1+p2+2*length+len(r1)+len(r2)+len(r3)))\n","            ny.append([\"sos\",\"o\",\"eos\"])\n","            nhmm_y.append([\"o\"]*(p1+p2+2*length+len(r1)+len(r2)+len(r3)))\n","            # ix = sorted(random.choices(range(len(other)),k = 4*length+len(r1)+len(r2)+len(r3)))\n","            # nx.append([other[i] for i in ix])\n","            # l = [label[i] for i in ix]\n","            # ny.append([\"sos\"]+sorted(set(l),key = l.index)+[\"eos\"])\n","            # nhmm_y.append(l)\n","    x,y,hmm_y = px+nx,py+ny,phmm_y+nhmm_y    \n","\n","    return x,y,hmm_y\n","\n","def generate_4_samples(s1,s2,s3,s4,other,label,length,numbers,k=1):\n","    \"\"\"\n","    numbers: 样本个数\n","    k：负样本比例\n","    \"\"\"\n","    px,py,phmm_y = [],[],[]\n","    nx,ny,nhmm_y = [],[],[]\n","\n","    for i in range(numbers):\n","        k1 = int(random.random()*len(s1)) if int(random.random()*len(s1))>= 1 else 1\n","        k2 = int(random.random()*len(s2)) if int(random.random()*len(s2))>= 1 else 1\n","        k3 = int(random.random()*len(s3)) if int(random.random()*len(s3))>= 1 else 1\n","        k4 = int(random.random()*len(s4)) if int(random.random()*len(s4))>= 1 else 1\n","        r1 = [s1[i] for i in sorted(random.choices(range(len(s1)),k=k1))]\n","        r2 = [s2[i] for i in sorted(random.choices(range(len(s2)),k=k2))]\n","        r3 = [s3[i] for i in sorted(random.choices(range(len(s3)),k=k3))]\n","        r4 = [s4[i] for i in sorted(random.choices(range(len(s4)),k=k4))]    \n","        p1 = random.randint(int(length*0.5),length)\n","        p2 = random.randint(int(length*0.5),length)\n","        px.append([other[i] for i in sorted(random.choices(range(len(other)),k = p1))]+\n","                  r1+ [other[i] for i in sorted(random.choices(range(len(other)),k = length))] +\n","                  r2 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))] + \n","                  r3+[other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r4 + [other[i] for i in sorted(random.choices(range(len(other)),k = p2))])\n","        py.append([\"sos\",\"s1\",\"s2\",\"s3\",\"s4\",\"eos\"])\n","        phmm_y.append([\"o\"]*p1+\n","                     [\"s1\"]*len(r1)+[\"o\"]*length+\n","                     [\"s2\"]*len(r2)+[\"o\"]*length+\n","                     [\"s3\"]*len(r3)+[\"o\"]*length+\n","                     [\"s4\"]*len(r4)+[\"o\"]*p2)\n","        if i%k == 0:\n","            nx.append(random.choices(other,k = p1+p2+3*length+len(r1)+len(r2)+len(r3)+len(r4)))\n","            ny.append([\"sos\",\"o\",\"eos\"])\n","            nhmm_y.append([\"o\"]*(p1+p2+3*length+len(r1)+len(r2)+len(r3)+len(r4)))\n","            # ix = sorted(random.choices(range(len(other)),k = p1+p2+*length+len(r1)+len(r2)+len(r3)+len(r4)))\n","            # nx.append([other[i] for i in ix])\n","            # l = [label[i] for i in ix]\n","            # ny.append([\"sos\"]+sorted(set(l),key = l.index)+[\"eos\"])\n","            # nhmm_y.append(l)\n","    x,y,hmm_y = px+nx,py+ny,phmm_y+nhmm_y    \n","    return x,y,hmm_y\n","\n","def generate_5_samples(s1,s2,s3,s4,s5,other,label,length,numbers,k=1):\n","    \"\"\"\n","    numbers: 样本个数\n","    k：负样本比例\n","    \"\"\"\n","    px,py,phmm_y = [],[],[]\n","    nx,ny,nhmm_y = [],[],[]\n","\n","    for i in range(numbers):\n","        k1 = int(random.random()*len(s1)) if int(random.random()*len(s1))>= 1 else 1\n","        k2 = int(random.random()*len(s2)) if int(random.random()*len(s2))>= 1 else 1\n","        k3 = int(random.random()*len(s3)) if int(random.random()*len(s3))>= 1 else 1\n","        k4 = int(random.random()*len(s4)) if int(random.random()*len(s4))>= 1 else 1\n","        k5 = int(random.random()*len(s5)) if int(random.random()*len(s5))>= 1 else 1\n","        r1 = [s1[i] for i in sorted(random.choices(range(len(s1)),k=k1))]\n","        r2 = [s2[i] for i in sorted(random.choices(range(len(s2)),k=k2))]\n","        r3 = [s3[i] for i in sorted(random.choices(range(len(s3)),k=k3))]\n","        r4 = [s4[i] for i in sorted(random.choices(range(len(s4)),k=k4))]\n","        r5 = [s5[i] for i in sorted(random.choices(range(len(s5)),k=k5))]    \n","        p1 = random.randint(int(length*0.5),length)\n","        p2 = random.randint(int(length*0.5),length)\n","\n","        px.append([other[i] for i in sorted(random.choices(range(len(other)),k = p1))]+\n","                  r1+ [other[i] for i in sorted(random.choices(range(len(other)),k = length))] +\n","                  r2 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))] + \n","                  r3+[other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r4 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r5 + [other[i] for i in sorted(random.choices(range(len(other)),k = p2))])\n","\n","        py.append([\"sos\",\"s1\",\"s2\",\"s3\",\"s4\",\"s5\",\"eos\"])\n","        phmm_y.append([\"o\"]*p1+[\"s1\"]*len(r1)+\n","                      [\"o\"]*length+[\"s2\"]*len(r2)+\n","                      [\"o\"]*length+[\"s3\"]*len(r3)+\n","                      [\"o\"]*length+[\"s4\"]*len(r4)+\n","                      [\"o\"]*length+[\"s5\"]*len(r5)+\n","                      [\"o\"]*p2)\n","        if i%k == 0:\n","            nx.append(random.choices(other,k = p1+p2+4*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)))\n","            ny.append([\"sos\",\"o\",\"eos\"])\n","            nhmm_y.append([\"o\"]*(p1+p2+4*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)))\n","            # ix = sorted(random.choices(range(len(other)),k = 6*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)))\n","            # nx.append([other[i] for i in ix])\n","            # l = [label[i] for i in ix]\n","            # ny.append([\"sos\"]+sorted(set(l),key = l.index)+[\"eos\"])\n","            # nhmm_y.append(l)\n","    x,y,hmm_y = px+nx,py+ny,phmm_y+nhmm_y    \n","    return x,y,hmm_y\n","\n","\n","def generate_6_samples(s1,s2,s3,s4,s5,s6,other,label,length,numbers,k=1):\n","    \"\"\"\n","    numbers: 样本个数\n","    k：负样本比例\n","    \"\"\"\n","    px,py,phmm_y = [],[],[]\n","    nx,ny,nhmm_y = [],[],[]\n","\n","    for i in range(numbers):\n","        k1 = int(random.random()*len(s1)) if int(random.random()*len(s1))>= 1 else 1\n","        k2 = int(random.random()*len(s2)) if int(random.random()*len(s2))>= 1 else 1\n","        k3 = int(random.random()*len(s3)) if int(random.random()*len(s3))>= 1 else 1\n","        k4 = int(random.random()*len(s4)) if int(random.random()*len(s4))>= 1 else 1\n","        k5 = int(random.random()*len(s5)) if int(random.random()*len(s5))>= 1 else 1\n","        k6 = int(random.random()*len(s6)) if int(random.random()*len(s6))>= 1 else 1\n","        r1 = [s1[i] for i in sorted(random.choices(range(len(s1)),k=k1))]\n","        r2 = [s2[i] for i in sorted(random.choices(range(len(s2)),k=k2))]\n","        r3 = [s3[i] for i in sorted(random.choices(range(len(s3)),k=k3))]\n","        r4 = [s4[i] for i in sorted(random.choices(range(len(s4)),k=k4))]\n","        r5 = [s5[i] for i in sorted(random.choices(range(len(s5)),k=k5))]\n","        r6 = [s6[i] for i in sorted(random.choices(range(len(s6)),k=k6))]    \n","        p1 = random.randint(int(length*0.5),length)\n","        p2 = random.randint(int(length*0.5),length)\n","\n","        px.append([other[i] for i in sorted(random.choices(range(len(other)),k = p1))]+\n","                  r1+ [other[i] for i in sorted(random.choices(range(len(other)),k = length))] +\n","                  r2 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))] + \n","                  r3+[other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r4 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r5 + [other[i] for i in sorted(random.choices(range(len(other)),k = length))]+\n","                  r6 + [other[i] for i in sorted(random.choices(range(len(other)),k = p2))])\n","\n","        py.append([\"sos\",\"s1\",\"s2\",\"s3\",\"s4\",\"s5\",\"s6\",\"eos\"])\n","        phmm_y.append([\"o\"]*p1+[\"s1\"]*len(r1)+\n","                      [\"o\"]*length+[\"s2\"]*len(r2)+\n","                      [\"o\"]*length+[\"s3\"]*len(r3)+\n","                      [\"o\"]*length+[\"s4\"]*len(r4)+\n","                      [\"o\"]*length+[\"s5\"]*len(r5)+\n","                      [\"o\"]*length+[\"s6\"]*len(r6)+\n","                      [\"o\"]*p2)\n","        if i%k == 0:\n","            nx.append(random.choices(other,k = p1+p2+5*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)+len(r6)))\n","            ny.append([\"sos\",\"o\",\"eos\"])\n","            nhmm_y.append([\"o\"]*(p1+p2+5*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)+len(r6)))\n","            # ix = sorted(random.choices(range(len(other)),k = 7*length+len(r1)+len(r2)+len(r3)+len(r4)+len(r5)+len(r6)))\n","            # nx.append([other[i] for i in ix])\n","            # l = [label[i] for i in ix]\n","            # ny.append([\"sos\"]+sorted(set(l),key = l.index)+[\"eos\"])\n","            # nhmm_y.append(l)\n","    x,y,hmm_y = px+nx,py+ny,phmm_y+nhmm_y    \n","    return x,y,hmm_y"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SUw7eW-P4R5C"},"source":["### seq2seq"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qCPB-ZQH4R5E","colab":{},"executionInfo":{"status":"ok","timestamp":1598146842096,"user_tz":-480,"elapsed":5832,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["class Seq2Seq:\n","    def __init__(self,alerts,labels,X,y,latent_dim,batch_size,epochs,max_single_channel_length, max_output_length=None, multi_channel=True, norm=True, verbose=0):\n","        \n","        self.latent_dim, self.batch_size, self.max_single_channel_length = latent_dim, batch_size, max_single_channel_length\n","        self.epochs = epochs\n","        self.verbose = verbose\n","        self.train_x,self.test_x,self.train_y,self.test_y = train_test_split(X,y,test_size=0.2)\n","        \n","        input_characters = list(set(alerts)) + ['eos']\n","        # target_characters = list(set(labels))+['sos','eos']\n","        tmp = []\n","        for yi in y:\n","            tmp.extend(yi)\n","        target_characters = list(set(tmp))\n","\n","        input_characters = sorted(list(input_characters))\n","        target_characters = sorted(list(target_characters))\n","        self.num_encoder_tokens = len(input_characters)\n","        self.num_decoder_tokens = len(target_characters)\n","        self.max_encoder_seq_length = max([len(txt) for txt in X])\n","        self.max_decoder_seq_length = max([len(txt) for txt in y])\n","\n","        self.max_output_length = max_output_length\n","        if not max_output_length:\n","            self.max_output_length = self.max_decoder_seq_length \n","\n","        print('Number of samples:', len(X))\n","        print('Number of unique input tokens:', self.num_encoder_tokens)\n","        print('Number of unique output tokens:', self.num_decoder_tokens)\n","        print('output tokens:', target_characters)\n","        print('Max sequence length for inputs:', self.max_encoder_seq_length)\n","        print('Max sequence length for outputs:', self.max_output_length )\n","\n","        self.input_token_index = dict(\n","            [(char, i) for i, char in enumerate(input_characters)])\n","        self.target_token_index = dict(\n","            [(char, i) for i, char in enumerate(target_characters)])\n","\n","        if not multi_channel:\n","            self._build_single_model()\n","            self.channels = 1\n","        else:\n","            self.channels = (self.max_encoder_seq_length) // self.max_single_channel_length\n","            if (self.max_encoder_seq_length) % self.max_single_channel_length != 0:\n","                self.channels += 1\n","            self._build_multi_model(norm = norm)\n","        \n","    def _prepare_data(self,x,y,max_encoder_seq_length, num_encoder_tokens,max_decoder_seq_length, num_decoder_tokens):\n","        encoder_input_data = np.zeros(\n","            (len(x), max_encoder_seq_length, num_encoder_tokens),\n","            dtype='float32')\n","        decoder_input_data = np.zeros(\n","            (len(x), max_decoder_seq_length, num_decoder_tokens),\n","            dtype='float32')\n","        decoder_target_data = np.zeros(\n","            (len(x), max_decoder_seq_length, num_decoder_tokens),\n","            dtype='float32')\n","\n","        for i, (input_text, target_text) in enumerate(zip(x, y)):\n","            for t, char in enumerate(input_text):\n","                encoder_input_data[i, t, self.input_token_index[char]] = 1.\n","            encoder_input_data[i, t + 1:, self.input_token_index['eos']] = 1.\n","            for t, char in enumerate(target_text):\n","                # decoder 输出比输入早一个step \n","                decoder_input_data[i, t, self.target_token_index[char]] = 1.\n","                if t > 0:\n","                    decoder_target_data[i, t - 1, self.target_token_index[char]] = 1.\n","            decoder_input_data[i, t + 1:, self.target_token_index['eos']] = 1.  #长度不足，用‘eos’填充\n","            decoder_target_data[i, t, self.target_token_index['eos']] = 1.  # 长度不足，用‘eos’填充\n","        return encoder_input_data, decoder_input_data, decoder_target_data\n","\n","    def _build_single_model(self):\n","        self.encoder_inputs = keras.layers.Input(shape=(None, self.num_encoder_tokens))\n","        encoder = keras.layers.LSTM(self.latent_dim, return_state=True)\n","        encoder_outputs, state_h, state_c = encoder(self.encoder_inputs)\n","        self.encoder_states = [state_h, state_c]\n","\n","        #decode\n","\n","        self.decoder_inputs = keras.layers.Input(shape=(None, self.num_decoder_tokens))\n","        self.decoder_lstm = keras.layers.LSTM(self.latent_dim, return_sequences=True, return_state=True)\n","        decoder_outputs, _, _ = self.decoder_lstm(self.decoder_inputs,initial_state = self.encoder_states)\n","        self.decoder_dense = keras.layers.Dense(self.num_decoder_tokens, activation='softmax')\n","        decoder_outputs = self.decoder_dense(decoder_outputs)\n","\n","        #model\n","        self.model = keras.Model([self.encoder_inputs, self.decoder_inputs], decoder_outputs)\n","\n","    def _build_multi_model(self,norm = False):\n","        self.encoder_inputs = []\n","        H, C = [], []\n","        for i in range(self.channels):\n","            self.encoder_inputs.append(keras.layers.Input(shape=(None, self.num_encoder_tokens)))\n","            encoder = keras.layers.LSTM(self.latent_dim, return_state=True)\n","            encoder_outputs, state_h, state_c = encoder(self.encoder_inputs[i])\n","            H.append(state_h)\n","            C.append(state_c)\n","        # k = int(np.sqrt(self.channels))+1 if self.channels>1 else 1\n","        # index = random.sample(range(self.channels), k=k)\n","        # if norm == True:\n","        #     self.encoder_states = [tf.reduce_mean([H[ix] for ix in index],axis=0),\n","                                #    tf.reduce_mean([C[ix] for ix in index],axis=0)]\n","        if norm == True:\n","            self.encoder_states = [tf.reduce_mean(H,axis=0),tf.reduce_mean(C,axis=0)]\n","        else:\n","            sum_h, sum_c = H[index[0]], C[index[0]]\n","            for ix in range(1,len(index)):\n","                sum_h = keras.layers.add([H[index[ix]],sum_h]) \n","                sum_c = keras.layers.add([C[index[ix]],sum_c]) \n","            self.encoder_states = [sum_h,sum_c]\n","\n","\n","        #decode\n","\n","        self.decoder_inputs = keras.layers.Input(shape=(None, self.num_decoder_tokens))\n","        self.decoder_lstm = keras.layers.LSTM(self.latent_dim, return_sequences=True, return_state=True)\n","        decoder_outputs, _, _ = self.decoder_lstm(self.decoder_inputs,initial_state = self.encoder_states)\n","        self.decoder_dense = keras.layers.Dense(self.num_decoder_tokens, activation='softmax')\n","        decoder_outputs = self.decoder_dense(decoder_outputs)\n","\n","        #model\n","        self.model = keras.Model([self.encoder_inputs, self.decoder_inputs], decoder_outputs)\n","\n","    def train(self):\n","        t0 = time.time()\n","        # Run training\n","        self.model.compile(optimizer='adam', loss='categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","        encoder_input_data, decoder_input_data, decoder_target_data = self._prepare_data(\n","            x = self.train_x,\n","            y = self.train_y,\n","            max_encoder_seq_length = self.max_encoder_seq_length, #modefiy 0808\n","            num_encoder_tokens = self.num_encoder_tokens,\n","            max_decoder_seq_length = self.max_decoder_seq_length, \n","            num_decoder_tokens = self.num_decoder_tokens\n","        )\n","\n","        inputs = []\n","        for i in range(self.channels):\n","            inputs.append(encoder_input_data[:,i::self.channels])\n","        inputs.append(decoder_input_data)\n","\n","        callbacks = [keras.callbacks.EarlyStopping(monitor = 'val_accuracy',patience=1)]\n","\n","        self.model.fit(inputs, decoder_target_data,\n","                  batch_size = self.batch_size,\n","                  epochs = self.epochs,\n","                  validation_split = 0.1,\n","                  verbose = self.verbose)\n","\n","        t1 = time.time()\n","        self.training_time = (t1 - t0)/len(self.train_y)\n","        print(\"training spend time:{}\".format(self.training_time))\n","        \n","    def evaluation(self):\n","        # #### testing\n","        self.reverse_input_char_index = dict(\n","            (i, char) for char, i in self.input_token_index.items())\n","        self.reverse_target_char_index = dict(\n","            (i, char) for char, i in self.target_token_index.items())\n","\n","        # Next: inference mode (sampling).\n","\n","        self.encoder_model = keras.Model(self.encoder_inputs, self.encoder_states)\n","\n","        decoder_state_input_h = keras.layers.Input(shape=(self.latent_dim,))\n","        decoder_state_input_c = keras.layers.Input(shape=(self.latent_dim,))\n","        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","        decoder_outputs, state_h, state_c = self.decoder_lstm(\n","            self.decoder_inputs, initial_state = decoder_states_inputs)\n","        decoder_states = [state_h, state_c]\n","        decoder_outputs = self.decoder_dense(decoder_outputs)\n","        self.decoder_model = keras.Model(\n","            [self.decoder_inputs] + decoder_states_inputs,\n","            [decoder_outputs] + decoder_states)\n","\n","\n","        encoder_input_data, decoder_input_data, decoder_target_data = self._prepare_data(\n","            x = self.test_x,\n","            y = self.test_y,\n","            max_encoder_seq_length = self.max_encoder_seq_length, \n","            num_encoder_tokens = self.num_encoder_tokens,\n","            max_decoder_seq_length = self.max_decoder_seq_length, \n","            num_decoder_tokens = self.num_decoder_tokens\n","        )\n","\n","        y_true = [yi[1:-1] for yi in self.test_y]\n","\n","        input_seq = [encoder_input_data[:,c::self.channels] for c in range(self.channels)]#encoder_input_data[i:i+1]\n","        decode_output = self._batch_decode_sequence(input_seq)\n","\n","        return y_true, decode_output\n","        \n","    def _batch_decode_sequence(self,input_seq):\n","        number_samples = input_seq[0].shape[0]\n","\n","        states_value = self.encoder_model.predict(input_seq)\n","        target_seq = np.zeros((number_samples, 1, self.num_decoder_tokens))\n","        for i in range(number_samples):\n","            target_seq[i, 0, self.target_token_index['sos']] = 1.\n","\n","        decoded_sentence = [[] for _ in range(number_samples)]\n","\n","        stop_condition = [False for _ in range(number_samples)]\n","        while not all(stop_condition):\n","\n","            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n","            sampled_token_index = np.argmax(output_tokens,axis = 2)\n","            sampled_char = [self.reverse_target_char_index[index[0]] for index in sampled_token_index]\n","\n","            for i in range(number_samples):\n","\n","                if sampled_char[i] == 'eos':# or len(decoded_sentence[i]) >= self.max_output_length:\n","                    stop_condition[i] = True\n","                else:\n","                    decoded_sentence[i].append(sampled_char[i])\n","\n","            # Update the target sequence (of length 1).\n","            target_seq = np.zeros((number_samples, 1, self.num_decoder_tokens))\n","            for i in range(number_samples):\n","                target_seq[i, 0, sampled_token_index[i]] = 1.\n","\n","            # Update states\n","            states_value = [h, c]\n","        return decoded_sentence"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2fvP0Wws4R5L"},"source":["### HMM"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rnAYR4J14R5N","colab":{},"executionInfo":{"status":"ok","timestamp":1598146842790,"user_tz":-480,"elapsed":5725,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["class HMM:\n","    def __init__(self,alerts,labels,x,y,use_bw = False):\n","        train_x,self.test_x,train_y,self.test_y = train_test_split(x, y,test_size=0.2)#,random_state=42\n","\n","#         states = list(set(labels))  #labels.unique().tolist()\n","        states = set()\n","        for yi in y:\n","            states = states | set(yi)\n","        states = list(states)\n","        print(states)\n","        obs = list(set(alerts))  #alerts.unique().tolist()\n","       \n","\n","        self.state_index = {s:index for index,s in enumerate(states)}\n","        self.obs_index = {o:index for index,o in enumerate(obs)}\n","\n","        self.index_state = {ix:s for s,ix in self.state_index.items()}\n","        self.index_obs = {ix:o for o,ix in self.obs_index.items()}\n","\n","        self.max_output_seq_length = max([len(set(txt)) for txt in y])\n","#         max_ouput_seq = [set(txt) for txt in y if len(set(txt)) >= max_output_seq_length]\n","\n","        print('Max sequence length for outputs:', self.max_output_seq_length)\n","        print('Number of train samples:', len(train_x))\n","        print('Number of test samples:', len(self.test_x))\n","        print('Number of states:', len(states))\n","        print('Number of obs:', len(obs))\n","\n","        self.A = self._transition_matrix(states,state_seq = train_y)\n","        self.B = self._emission_matrix(states,obs,state_seq = train_y, obs_seq = train_x)\n","        self.pi = self._pi_vector(states,state_seq = train_y)\n","        if not use_bw:\n","            self.model = self.hmm_kit(states,obs)\n","        else:\n","            self.model = self.bw_hmm(states,obs,x)\n","        \n","    # HMM 参数计算 监督学习\n","\n","    # 转移概率  \n","    def _transition_matrix(self,states,state_seq):\n","        # 状态数\n","        state_number = len(states)\n","        A = [[0]*state_number for _ in range(state_number)]\n","\n","        count = {}\n","        for si in states:\n","            count[si] = {}\n","            for sj in states:\n","                count[si].setdefault(sj, 0)\n","\n","        #状态转移频数\n","        for seq in state_seq:\n","            index = 0\n","            while index < len(seq)-1:\n","                count[seq[index]][seq[index+1]] += 1\n","                index += 1\n","\n","        for i in range(state_number):\n","            count_i = sum(count[states[i]].values())\n","            for j in range(state_number):\n","                A[i][j] = count[states[i]][states[j]] / (count_i+0.000001)\n","\n","        return A\n","\n","    # 发射概率\n","    def _emission_matrix(self,states,obs,state_seq,obs_seq):\n","        # 状态数\n","        state_number = len(states)\n","        obs_number = len(obs)\n","        B = [[0]*obs_number for _ in range(state_number)]\n","\n","        count = {}\n","        for si in states:\n","            count[si] = {}\n","            for sj in obs:\n","                count[si].setdefault(sj, 0)\n","\n","        #状态到观测的发射频数\n","        for s_seq,o_seq in zip(state_seq,obs_seq):\n","            for i in range(len(s_seq)):\n","                count[s_seq[i]][o_seq[i]] += 1\n","\n","        for i in range(state_number):\n","            count_i = sum(count[states[i]].values())\n","            for j in range(obs_number):\n","                B[i][j] = count[states[i]][obs[j]] / (count_i+0.000001)\n","\n","        return B\n","\n","\n","    # 初始状态概率\n","    def _pi_vector(self,states,state_seq):\n","        # 所有样本中初始状态为 q 的概率\n","        count = {}\n","        for s in states:\n","            count.setdefault(s,0)\n","\n","        for seq in state_seq:\n","            if seq:\n","                count[seq[0]] += 1\n","\n","        pi = np.array([freq/len(state_seq) for freq in count.values()])\n","        return pi/sum(pi)\n","\n","\n","    def _hmm_viterbi(self,A,B,pi,O):\n","        T = len(O)\n","        N = len(A[0])\n","\n","        delta = [[0]*N for _ in range(T)]\n","        psi = [[0]*N for _ in range(T)]\n","\n","        #step1: init\n","        for i in range(N):\n","            delta[0][i] = pi[i]*B[i][self.obs_index[O[0]]]\n","            psi[0][i] = 0\n","\n","        #step2: iter\n","        for t in range(1,T):\n","            for i in range(N):\n","                temp,maxindex = 0,0\n","                for j in range(N):\n","                    res = delta[t-1][j]*A[j][i]\n","                    if res>temp:\n","                        temp = res\n","                        maxindex = j\n","\n","                delta[t][i] = temp*B[i][self.obs_index[O[t]]]#delta\n","                psi[t][i] = maxindex\n","\n","        #step3: end\n","        p = max(delta[-1])\n","        for i in range(N):\n","            if delta[-1][i] == p:\n","                i_T = i\n","\n","        #step4：backtrack\n","        path = [0]*T\n","        i_t = i_T\n","        for t in reversed(range(T-1)):\n","            i_t = psi[t+1][i_t]\n","            path[t] = i_t\n","        path[-1] = i_T\n","\n","        return delta,psi,path  \n","   \n","    def evaluation(self):\n","#         y_true = [sorted(set(yi), key=yi.index) for yi in self.test_y]\n","        y_true = self.test_y\n","        y_pred = []\n","        for i in range(len(self.test_x)):\n","            # _, _, path = self._hmm_viterbi(self.A, self.B, self.pi, self.test_x[i])\n","            seen = np.array([self.obs_index[self.test_x[i][t]] for t in range(len(self.test_x[i]))]).reshape(-1,1)\n","            path = self.model.predict(seen).tolist()\n","            y_pred.append([self.index_state[s] for s in path])\n","#             y_pred.append([self.index_state[s] for s in sorted(set(path), key=path.index)])\n","        return y_true, y_pred\n","    \n","    def hmm_kit(self,states,obs):\n","        from hmmlearn import hmm\n","\n","        n_states = len(states)\n","        n_observations = len(obs)\n","\n","        start_probability = self.pi\n","        transition_probability = self.A\n","        emission_probability = self.B\n","\n","        model = hmm.MultinomialHMM(n_components=n_states)\n","        model.startprob_=start_probability\n","        model.transmat_=transition_probability\n","        model.emissionprob_=emission_probability\n","        return model\n","    \n","    def bw_hmm(self,states,obs,x):\n","        from hmmlearn import hmm\n","        n_states = len(states)\n","        n_observations = len(obs)\n","\n","        model = hmm.MultinomialHMM(n_components=n_states, n_iter=10, tol=0.01)\n","\n","        O = []\n","        for xi in x:\n","            o_seq = [self.obs_index[o] for o in xi]\n","            O.append(o_seq)\n","\n","        model.fit(np.array(O))\n","        return model"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pB0JCgo44R5T"},"source":["### main"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0_LVY95fVNOo","colab":{},"executionInfo":{"status":"ok","timestamp":1598146842792,"user_tz":-480,"elapsed":4993,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}}},"source":["path = \"/content/drive/My Drive/Colab Notebooks/MSA/\"\n","# path = \"./\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"OqFwJlBC7If-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598146842793,"user_tz":-480,"elapsed":4137,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"163f6470-dafd-49fe-c978-3734b9f97c79"},"source":["input_file = path + \"data/darpa_alert.csv\" \n","print(input_file)\n","alerts, labels = dataLoader(input_file)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MSA/data/darpa_alert.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x1RBEzpr7GmJ"},"source":["#### seq2seq vs. hmm 2 stage"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pGjlY2tR7GmM","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598004213835,"user_tz":-480,"elapsed":1187,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"db589394-11ea-4f93-8289-18ab188e8fe2"},"source":["\n","output_file = path + \"results/\"+ datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_darpa_2_stage_eva52.csv\"\n","\n","print(output_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MSA/results/20200821100332_darpa_2_stage_eva52.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"POKRjx3J7GmS","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598004214974,"user_tz":-480,"elapsed":827,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"5bdb1c79-63ba-4b60-a03d-f58564ef39c2"},"source":["data = pd.read_csv(input_file)\n","\n","s1 = data[data.stage == \"s1\"].event.tolist()\n","s2 = data[data.stage == \"s2\"].event.tolist()\n","s3 = data[data.stage == \"s3\"].event.tolist()\n","s4 = data[data.stage == \"s4\"].event.tolist()\n","s5 = data[data.stage == \"s5\"].event.tolist()\n","\n","other = data[(data.stage != \"s1\") & (data.stage != \"s2\")].event.tolist()\n","label = data[(data.stage != \"s1\") & (data.stage != \"s2\")].stage.tolist()\n","print(len(s1),len(s2),len(other))\n","\n","stages = [\"s1\",\"s2\"]\n","output_length = len(stages)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["293 109 3531\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-GTrTbJd8XYk","colab_type":"code","colab":{}},"source":["# import pickle   \n","\n","# with open(path+\"temp/darpa_x_stage_2_len_\"+str(length)+\".pickle\",'rb') as f:\n","#     X = pickle.load(f)\n","# with open(path+\"temp/darpa_y_stage_2_len_\"+str(length)+\".pickle\",'rb') as f:\n","#     y = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lJBm7pG17GmV","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598020777548,"user_tz":-480,"elapsed":5191124,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"69ed7a08-8a51-4463-9f10-9cce4bbcbb8b"},"source":["for length in [1000,1500,2000]: # 100 500 1000 1500 2000 2500 3000\n","    for epoch in range(5):\n","        print(\"------------- epoch {} n_steps :{} -----------\".format(epoch, length))\n","\n","        ## run seq2seq\n","        \n","        X, y, hmm_y = generate_2_samples(s1,s2,other,label,length = length, numbers = 1500,k=1)\n","\n","        # with open(path+\"temp/darpa_x_stage_2_len_\"+str(length)+\".pickle\",'wb') as f:\n","        #     pickle.dump(X,f)\n","        # with open(path+\"temp/darpa_y_stage_2_len_\"+str(length)+\".pickle\",'wb') as f:\n","        #     pickle.dump(y,f)\n","\n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 8,\n","                        max_single_channel_length = 200,\n","                        verbose = 0\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        precision, recall, f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","        \n","        # hmm\n","        hmm = HMM(alerts = alerts,\n","                  labels = labels,\n","                  x = X,\n","                  y = hmm_y)\n","        hmm_true, hmm_output = hmm.evaluation()\n","        hmm_precision, hmm_recall, hmm_f1 = eva_metrics1(hmm_true,hmm_output,stages = stages,hmm=True)\n","\n","        csvFile = open(output_file,'a+',newline='')\n","        try:\n","            writer=csv.writer(csvFile)\n","            writer.writerow((input_file, len(X), length,\n","                             np.mean([len(xi) for xi in X]), seq2seq.max_encoder_seq_length, \n","                             output_length, 'seq2seq-hmm',\n","                             precision, hmm_precision,recall,hmm_recall, f1, hmm_f1))\n","        finally:\n","            csvFile.close()\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------- epoch 0 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3310\n","Max sequence length for outputs: 4\n","training spend time:0.271069896419843\n","precison:  0.950920245398773\n","recall:  1.0\n","f1:  0.9748427672955975\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.7012452263838721\n","recall:  0.8923333333333365\n","f1:  0.7853324663884201\n","------------- epoch 1 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3308\n","Max sequence length for outputs: 4\n","training spend time:0.2966631856560707\n","precison:  0.9235294117647059\n","recall:  1.0\n","f1:  0.9602446483180428\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6805617053322534\n","recall:  0.888000000000003\n","f1:  0.7705642593219252\n","------------- epoch 2 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3306\n","Max sequence length for outputs: 4\n","training spend time:0.3060777940352758\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.684661009994029\n","recall:  0.8898888888888922\n","f1:  0.7739001804660328\n","------------- epoch 3 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3295\n","Max sequence length for outputs: 4\n","training spend time:0.30705295940240224\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6831941307173504\n","recall:  0.8917777777777807\n","f1:  0.7736739181133462\n","------------- epoch 4 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3278\n","Max sequence length for outputs: 4\n","training spend time:0.3081707551081975\n","precison:  1.0\n","recall:  0.9409722222222222\n","f1:  0.9695885509838997\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.696766049782068\n","recall:  0.8924444444444466\n","f1:  0.7825583740663102\n","------------- epoch 0 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4775\n","Max sequence length for outputs: 4\n","training spend time:0.4406464324394862\n","precison:  0.9967320261437909\n","recall:  1.0\n","f1:  0.9983633387888707\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6019797479321339\n","recall:  0.8695555555555594\n","f1:  0.7114404022868895\n","------------- epoch 1 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4793\n","Max sequence length for outputs: 4\n","training spend time:0.4452849617600441\n","precison:  0.9965753424657534\n","recall:  1.0\n","f1:  0.9982847341337907\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6074479667025376\n","recall:  0.8697777777777815\n","f1:  0.7153202475225398\n","------------- epoch 2 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4806\n","Max sequence length for outputs: 4\n","training spend time:0.4542608726024628\n","precison:  0.978978978978979\n","recall:  1.0\n","f1:  0.9893778452200305\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.620524581379687\n","recall:  0.8797777777777815\n","f1:  0.7277516214388758\n","------------- epoch 3 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4774\n","Max sequence length for outputs: 4\n","training spend time:0.4430070435007413\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6137768104957808\n","recall:  0.8722222222222257\n","f1:  0.7205250633574154\n","------------- epoch 4 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4753\n","Max sequence length for outputs: 4\n","training spend time:0.4410558605194092\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.6303086328809403\n","recall:  0.8727777777777816\n","f1:  0.7319863502443494\n","------------- epoch 0 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6293\n","Max sequence length for outputs: 4\n","training spend time:0.5865194435914357\n","precison:  0.9712460063897763\n","recall:  1.0\n","f1:  0.9854132901134521\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.5648652261770188\n","recall:  0.8588888888888937\n","f1:  0.6815172105201509\n","------------- epoch 1 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6228\n","Max sequence length for outputs: 4\n","training spend time:0.5819144993027051\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.5730753433210558\n","recall:  0.8687777777777821\n","f1:  0.6906044949852801\n","------------- epoch 2 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6270\n","Max sequence length for outputs: 4\n","training spend time:0.5868276101350784\n","precison:  0.9506578947368421\n","recall:  1.0\n","f1:  0.9747048903878585\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.5761586689356128\n","recall:  0.8698888888888926\n","f1:  0.6931916196423317\n","------------- epoch 3 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6222\n","Max sequence length for outputs: 4\n","training spend time:0.5849113148450852\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.5744973046617684\n","recall:  0.8598888888888926\n","f1:  0.6888017344233088\n","------------- epoch 4 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6289\n","Max sequence length for outputs: 4\n","training spend time:0.5867796483635902\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 'o']\n","Max sequence length for outputs: 3\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 3\n","Number of obs: 17\n","precison:  0.5899146499259601\n","recall:  0.8664444444444482\n","f1:  0.7019261569492284\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S4R6gYQY2PEE"},"source":["#### seq2seq vs. hmm 3 stage"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MvUkkaohhWQ_","colab":{}},"source":["output_file = path + \"results/\"+ datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_darpa_3_stage_eva52.csv\"\n","# print(output_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okI-2dd7KD83","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598021613937,"user_tz":-480,"elapsed":1111,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"2beeffa1-f16a-4037-c772-6800c43dc922"},"source":["data = pd.read_csv(input_file)\n","\n","s1 = data[data.stage == \"s1\"].event.tolist()\n","s2 = data[data.stage == \"s2\"].event.tolist()\n","s3 = data[data.stage == \"s3\"].event.tolist()\n","s4 = data[data.stage == \"s4\"].event.tolist()\n","s5 = data[data.stage == \"s5\"].event.tolist()\n","\n","other = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\")].event.tolist()\n","label = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\")].stage.tolist()\n","print(len(s1),len(s2),len(s3),len(other))\n","\n","stages = [\"s1\",\"s2\",\"s3\"]\n","output_length = len(stages)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["293 109 81 3450\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H3RhrgzlzOic","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9bf89e2c-1968-4b5d-f2bb-6164897c585e"},"source":["for length in [100,500,1000,1500,2000]: # darpa 100,420,900,1280,2500 #800,1300,1800,5350,7100,9700\n","    for epoch in range(5):\n","        print(\"------------- epoch {} n_steps :{} -----------\".format(epoch, length))\n","\n","        ## run seq2seq\n","        \n","        X, y, hmm_y = generate_3_samples(s1,s2,s3,other,label,length = length, numbers = 1500,k=1)\n","        \n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 8,\n","                        max_single_channel_length = 200,\n","                        verbose = 0\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        precision, recall, f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","        # hmm\n","        hmm = HMM(alerts = alerts,\n","                  labels = labels,\n","                  x = X,\n","                  y = hmm_y)\n","        hmm_true, hmm_output = hmm.evaluation()\n","        hmm_precision, hmm_recall, hmm_f1 = eva_metrics2(hmm_true,hmm_output,stages = stages)\n","\n","        csvFile = open(output_file,'a+',newline='')\n","        try:\n","            writer=csv.writer(csvFile)\n","            writer.writerow((input_file, len(X), length,\n","                             np.mean([len(xi) for xi in X]), seq2seq.max_encoder_seq_length, \n","                             output_length, 'seq2seq-hmm',\n","                             precision, hmm_precision,recall,hmm_recall, f1, hmm_f1))\n","        finally:\n","            csvFile.close() "],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------- epoch 0 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 849\n","Max sequence length for outputs: 5\n","training spend time:0.08231138666470846\n","precison:  0.587890625\n","recall:  0.9435736677115988\n","f1:  0.7244283995186523\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9770747765453088\n","recall:  0.9985972316616651\n","f1:  0.9877187740996424\n","------------- epoch 1 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 832\n","Max sequence length for outputs: 5\n","training spend time:0.08243245442708333\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9774705321034628\n","recall:  0.9989421688662435\n","f1:  0.988089717155932\n","------------- epoch 2 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 825\n","Max sequence length for outputs: 5\n","training spend time:0.0824788369735082\n","precison:  1.0\n","recall:  0.5217391304347826\n","f1:  0.6857142857142856\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9786463037369525\n","recall:  0.9990463407453988\n","f1:  0.9887411083417593\n","------------- epoch 3 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 835\n","Max sequence length for outputs: 5\n","training spend time:0.08387388745943705\n","precison:  0.8672566371681416\n","recall:  0.9865771812080537\n","f1:  0.923076923076923\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9767291674287115\n","recall:  0.998846768592371\n","f1:  0.9876641589803958\n","------------- epoch 4 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 808\n","Max sequence length for outputs: 5\n","training spend time:0.07972172637780507\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9795485286084605\n","recall:  0.9990709147841959\n","f1:  0.9892134112200344\n","------------- epoch 0 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 2372\n","Max sequence length for outputs: 5\n","training spend time:0.22551731675863265\n","precison:  0.5396290050590219\n","recall:  1.0\n","f1:  0.7009857612267251\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9439996185983792\n","recall:  0.9990166961384581\n","f1:  0.9707292450149574\n","------------- epoch 1 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 2346\n","Max sequence length for outputs: 5\n","training spend time:0.21969093322753908\n","precison:  0.9967213114754099\n","recall:  1.0\n","f1:  0.9983579638752053\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9460542391735663\n","recall:  0.9994858738796117\n","f1:  0.97203634264215\n","------------- epoch 2 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 2369\n","Max sequence length for outputs: 5\n","training spend time:0.22323709229628244\n","precison:  1.0\n","recall:  0.026755852842809364\n","f1:  0.05211726384364821\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9495938955130585\n","recall:  0.9988129259078096\n","f1:  0.9735817456335193\n","------------- epoch 3 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 2375\n","Max sequence length for outputs: 5\n","training spend time:0.22626741369565329\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9479721494033563\n","recall:  0.9993382621271638\n","f1:  0.9729777386494032\n","------------- epoch 4 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 2390\n","Max sequence length for outputs: 5\n","training spend time:0.2237964951992035\n","precison:  0.9618055555555556\n","recall:  0.8993506493506493\n","f1:  0.9295302013422819\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.949369381698301\n","recall:  0.9991564735650172\n","f1:  0.9736268687079734\n","------------- epoch 0 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 4364\n","Max sequence length for outputs: 5\n","training spend time:0.40231505274772644\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9120381532199436\n","recall:  0.9993929623597552\n","f1:  0.9537194453959328\n","------------- epoch 1 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 4350\n","Max sequence length for outputs: 5\n","training spend time:0.4006296692291896\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9150745988585915\n","recall:  0.9988012001793887\n","f1:  0.955106499651701\n","------------- epoch 2 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 4315\n","Max sequence length for outputs: 5\n","training spend time:0.39954671541849773\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.916661043446807\n","recall:  0.9988896635077528\n","f1:  0.9560104443228056\n","------------- epoch 3 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 4325\n","Max sequence length for outputs: 5\n","training spend time:0.3928876628478368\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9143617427568762\n","recall:  0.9986491486688747\n","f1:  0.9546485909434602\n","------------- epoch 4 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 4356\n","Max sequence length for outputs: 5\n","training spend time:0.3792367089788119\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.9040268949500817\n","recall:  0.9992095841646557\n","f1:  0.9492381505811601\n","------------- epoch 0 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 6329\n","Max sequence length for outputs: 5\n","training spend time:0.5980508305629094\n","precison:  0.9968354430379747\n","recall:  1.0\n","f1:  0.9984152139461173\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.87787671089104\n","recall:  0.9991931320109452\n","f1:  0.9346145361523326\n","------------- epoch 1 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 6357\n","Max sequence length for outputs: 5\n","training spend time:0.5967489219705264\n","precison:  0.9869706840390879\n","recall:  1.0\n","f1:  0.9934426229508196\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8767952401357445\n","recall:  0.9984812727155162\n","f1:  0.933690174523167\n","------------- epoch 2 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 6359\n","Max sequence length for outputs: 5\n","training spend time:0.6122060548265775\n","precison:  0.9015384615384615\n","recall:  1.0\n","f1:  0.948220064724919\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8824468443373903\n","recall:  0.9991987162856821\n","f1:  0.9372006848731911\n","------------- epoch 3 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 6314\n","Max sequence length for outputs: 5\n","training spend time:0.6155274145801862\n","precison:  0.8796561604584527\n","recall:  1.0\n","f1:  0.9359756097560976\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8700506224484028\n","recall:  0.9991593279530889\n","f1:  0.9301461240605848\n","------------- epoch 4 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 6349\n","Max sequence length for outputs: 5\n","training spend time:0.6088611228267352\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8792718695328657\n","recall:  0.9992773274727553\n","f1:  0.9354415048690855\n","------------- epoch 0 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 8303\n","Max sequence length for outputs: 5\n","training spend time:0.7702482344706854\n","precison:  0.9896907216494846\n","recall:  1.0\n","f1:  0.9948186528497409\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.7986043162290524\n","recall:  0.9994464904715897\n","f1:  0.8878083735522344\n","------------- epoch 1 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 8260\n","Max sequence length for outputs: 5\n","training spend time:0.7356158217787743\n","precison:  0.996969696969697\n","recall:  1.0\n","f1:  0.9984825493171471\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8264018579665228\n","recall:  0.9992895924085896\n","f1:  0.9046597393479531\n","------------- epoch 2 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 8313\n","Max sequence length for outputs: 5\n","training spend time:0.7410142455498377\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.7924193543611344\n","recall:  0.9991516752346082\n","f1:  0.8838579239327253\n","------------- epoch 3 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 8341\n","Max sequence length for outputs: 5\n","training spend time:0.7688957407077154\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","['s2', 's1', 's3', 'o']\n","Max sequence length for outputs: 4\n","Number of train samples: 2400\n","Number of test samples: 600\n","Number of states: 4\n","Number of obs: 17\n","precison:  0.8027017646880242\n","recall:  0.9992542690699253\n","f1:  0.8902583083358566\n","------------- epoch 4 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 6\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 'sos']\n","Max sequence length for inputs: 8243\n","Max sequence length for outputs: 5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iHXoX5PVkrSz"},"source":["#### seq2seq vs. hmm 4 stage"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1aJgcjblkrS0","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597751072242,"user_tz":-480,"elapsed":1258,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"adb9a7ba-18c2-4445-f935-f1de239e4810"},"source":["output_file = path + \"results/\"+ datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_iscx_4_stage.csv\"\n","print(output_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MSA/results/20200818114431_iscx_4_stage_eva1.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ODx2XmwFkrS2","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597751111642,"user_tz":-480,"elapsed":1580,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"3ad35bb6-dafe-4bbf-aaa5-bc370714b336"},"source":["data = pd.read_csv(input_file)\n","\n","s1 = data[data.stage == \"s1\"].event.tolist()\n","s2 = data[data.stage == \"s2\"].event.tolist()\n","s3 = data[data.stage == \"s3\"].event.tolist()\n","s4 = data[data.stage == \"s4\"].event.tolist()\n","s5 = data[data.stage == \"s5\"].event.tolist()\n","\n","other = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\") & (data.stage != \"s4\")].event.tolist()\n","label = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\") & (data.stage != \"s4\")].stage.tolist()\n","print(len(s1),len(s2),len(s3),len(other))\n","\n","stages = [\"s1\",\"s2\",\"s3\",\"s4\"]\n","output_length = len(stages)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["78 1240 249 18345\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h0MAmYIjkrS5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597751756246,"user_tz":-480,"elapsed":641256,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"4535f70f-3f86-4f39-92f4-4bf43e49faeb"},"source":["\n","for epoch in range(10):\n","    for length in [100,500,1000,1500,2000]: # darpa 100,420,900,1280,2500 #800,1300,1800,5350,7100,9700\n","\n","        print(\"------------- epoch {} n_steps :{} -----------\".format(epoch, length))\n","\n","        ## run seq2seq\n","        \n","        X, y, hmm_y = generate_4_samples(s1,s2,s3,s4,other,label,length = length, numbers = 1000)\n","        \n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 5,\n","                        max_single_channel_length = 200, \n","                        max_output_length = output_length\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        precision, recall, f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","        # csvFile = open(output_file,'a+',newline='')\n","        # try:\n","        #     writer=csv.writer(csvFile)\n","        #     writer.writerow((input_file, len(X), len(X[0]), output_length, 'seq2seq', \n","        #                      precision, recall, f1, seq2seq.training_time, \n","        #                      seq2seq.latent_dim, seq2seq.batch_size, seq2seq.epochs, seq2seq.max_single_channel_length))\n","        # finally:\n","        #     csvFile.close()\n","\n","        hmm = HMM(alerts = alerts,\n","                  labels = labels,\n","                  x = X,\n","                  y = hmm_y)\n","        hmm_true, hmm_output = hmm.evaluation()\n","        hmm_precision, hmm_recall, hmm_f1 = eva_metrics2(hmm_true,hmm_output,stages = stages)\n","\n","        csvFile = open(output_file,'a+',newline='')\n","        try:\n","            writer=csv.writer(csvFile)\n","            writer.writerow((input_file, len(X), length,\n","                             np.mean([len(xi) for xi in X]), seq2seq.max_encoder_seq_length, \n","                             output_length, 'seq2seq-hmm',\n","                             precision, hmm_precision,recall,hmm_recall, f1, hmm_f1))\n","        finally:\n","            csvFile.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------- epoch 0 n_steps :100 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 2812\n","Max sequence length for outputs: 4\n","training spend time:0.03936794772744179\n","precison:  0.9999990000010001\n","recall:  0.005263157867036012\n","f1:  0.01047119366245454\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.28925789495483195\n","recall:  0.5499165290190146\n","f1:  0.3791047569807415\n","------------- epoch 0 n_steps :500 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 2776\n","Max sequence length for outputs: 4\n","training spend time:0.041680358499288556\n","precison:  0.9999999913043479\n","recall:  0.5373831750589572\n","f1:  0.6990876869211478\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.28761072884546246\n","recall:  0.5436665305815144\n","f1:  0.3762021328868134\n","------------- epoch 0 n_steps :1000 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 3733\n","Max sequence length for outputs: 4\n","training spend time:0.052945071309804914\n","precison:  0.9999999949238579\n","recall:  0.9999999949238579\n","f1:  0.999999494924108\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.42750928210972994\n","recall:  0.49980543059987653\n","f1:  0.4608386505302536\n","------------- epoch 0 n_steps :1500 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 5614\n","Max sequence length for outputs: 4\n","training spend time:0.060825348049402234\n","precison:  0.49999999875\n","recall:  0.999999995\n","f1:  0.666666220000296\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.27987315611063496\n","recall:  0.5426248644437822\n","f1:  0.3692797914667892\n","------------- epoch 0 n_steps :2000 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 2820\n","Max sequence length for outputs: 4\n","training spend time:0.0399521042406559\n","precison:  0.9999999950738917\n","recall:  0.9950980343377548\n","f1:  0.9975424926443355\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.30675937977811324\n","recall:  0.5782498554542012\n","f1:  0.4008621820500219\n","------------- epoch 0 n_steps :2500 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 4179\n","Max sequence length for outputs: 4\n","training spend time:0.054580878764390946\n","precison:  0.0\n","recall:  0.0\n","f1:  0.0\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.2649386795467882\n","recall:  0.5101804284264966\n","f1:  0.34876279855867015\n","------------- epoch 0 n_steps :3000 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 58\n","Number of unique output tokens: 9\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 's6', 'sos']\n","Max sequence length for inputs: 3775\n","Max sequence length for outputs: 4\n","training spend time:0.053451744616031645\n","precison:  0.9999999947368422\n","recall:  0.9895833281792535\n","f1:  0.9947638927115258\n","['s3', 's1', 's6', 's2', 's5', 'o', 's4']\n","Max sequence length for outputs: 5\n","Number of train samples: 1600\n","Number of test samples: 400\n","Number of states: 7\n","Number of obs: 57\n","precison:  0.29462148523194676\n","recall:  0.5618609709418545\n","f1:  0.38654877116309766\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BuQfYq7BktHj"},"source":["#### seq2seq vs. hmm 5 stage"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Mm00juf6ktHl","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598146849293,"user_tz":-480,"elapsed":934,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"b2d4b27c-7dbc-4a46-b5bd-05bdeeb33d1b"},"source":["output_file = path + \"results/\"+ datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_darpa_5_stage.csv\"\n","print(output_file)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MSA/results/20200823014048_darpa_5_stage.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_52fT3KGktHn","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598146849787,"user_tz":-480,"elapsed":857,"user":{"displayName":"gy zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWJ90-dZfihdqBe8roor-vAuJ6Hlr_NfnMYLpO=s64","userId":"06310788861102667590"}},"outputId":"3beb98d4-6366-454e-d894-6e51cc2e59ee"},"source":["data = pd.read_csv(input_file)\n","\n","s1 = data[data.stage == \"s1\"].event.tolist()\n","s2 = data[data.stage == \"s2\"].event.tolist()\n","s3 = data[data.stage == \"s3\"].event.tolist()\n","s4 = data[data.stage == \"s4\"].event.tolist()\n","s5 = data[data.stage == \"s5\"].event.tolist()\n","\n","other = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\") & (data.stage != \"s4\") & (data.stage != \"s5\")].event.tolist()\n","label = data[(data.stage != \"s1\") & (data.stage != \"s2\") & (data.stage != \"s3\") & (data.stage != \"s4\") & (data.stage != \"s5\")].stage.tolist()\n","print(len(s1),len(s2),len(s3),len(s4),len(s5),len(other))\n","\n","stages = [\"s1\",\"s2\",\"s3\",\"s4\",\"s5\"]\n","output_length = len(stages)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["293 109 81 2 2030 1418\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-dGQrFqtktHq","colab":{"base_uri":"https://localhost:8080/","height":359},"outputId":"e9303ebf-ae78-459d-8d68-106c3ee34aa1"},"source":["for length in [2000]:\n","    for epoch in range(10):\n","    \n","        print(\"------------- epoch {} n_steps :{} -----------\".format(epoch, length))\n","\n","        ## run seq2seq\n","        \n","        X, y, hmm_y = generate_5_samples(s1,s2,s3,s4,s5,other,label,length = length, numbers = 1000)\n","        \n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 15,\n","                        max_single_channel_length = 200, \n","                        max_output_length = output_length\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        precision, recall, f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","\n","        # hmm = HMM(alerts = alerts,\n","        #           labels = labels,\n","        #           x = X,\n","        #           y = hmm_y)\n","        # hmm_true, hmm_output = hmm.evaluation()\n","        # hmm_precision, hmm_recall, hmm_f1 = eva_metrics2(hmm_true,hmm_output,stages = stages)\n","\n","        csvFile = open(output_file,'a+',newline='')\n","        try:\n","            writer=csv.writer(csvFile)\n","            writer.writerow((input_file, len(X), length,\n","                             np.mean([len(xi) for xi in X]), seq2seq.max_encoder_seq_length, \n","                             output_length, 'seq2seq-hmm',\n","                             precision, recall, f1))\n","        finally:\n","            csvFile.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------- epoch 0 n_steps :2000 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 8\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 'sos']\n","Max sequence length for inputs: 14236\n","Max sequence length for outputs: 5\n","training spend time:1.7740791887044907\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","------------- epoch 1 n_steps :2000 -----------\n","Number of samples: 2000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 8\n","output tokens: ['eos', 'o', 's1', 's2', 's3', 's4', 's5', 'sos']\n","Max sequence length for inputs: 14073\n","Max sequence length for outputs: 5\n","training spend time:1.743356636762619\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4eFGmIUCJhB3","colab_type":"text"},"source":["### multi_channel vs. single"]},{"cell_type":"code","metadata":{"id":"AKVUi8lUJlaQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597931743019,"user_tz":-480,"elapsed":1044,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"1c9bfea5-4749-4cec-dd82-92cacb623712"},"source":["\n","output_file = path + \"results/\"+ datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_darpa_2_stage_channel.csv\"\n","\n","print(output_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MSA/results/20200820135542_darpa_2_stage_channel.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ee5ukrEJtGV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597931746448,"user_tz":-480,"elapsed":1242,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"291fbcf1-f2dd-405d-9735-f5396e0dbb0e"},"source":["data = pd.read_csv(input_file)\n","\n","s1 = data[data.stage == \"s1\"].event.tolist()\n","s2 = data[data.stage == \"s2\"].event.tolist()\n","s3 = data[data.stage == \"s3\"].event.tolist()\n","s4 = data[data.stage == \"s4\"].event.tolist()\n","s5 = data[data.stage == \"s5\"].event.tolist()\n","\n","other = data[(data.stage != \"s1\") & (data.stage != \"s2\")].event.tolist()\n","label = data[(data.stage != \"s1\") & (data.stage != \"s2\")].stage.tolist()\n","print(len(s1),len(s2),len(other))\n","\n","stages = [\"s1\",\"s2\"]\n","output_length = len(stages)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["293 109 3531\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"coLssaHSJx3h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597963092916,"user_tz":-480,"elapsed":21279399,"user":{"displayName":"gy zhou","photoUrl":"","userId":"06310788861102667590"}},"outputId":"4ee5027f-c212-4574-c52c-28aef5319e56"},"source":["logs = []\n","for epoch in range(5):\n","    for length in [100,500,1000,1500,2000]: # 100 500 1000 1500 2000 2500 3000\n","\n","        print(\"------------- epoch {} n_steps :{} -----------\".format(epoch, length))\n","\n","        ## run seq2seq\n","        \n","        X, y, hmm_y = generate_2_samples(s1,s2,other,label,length = length, numbers = 1500,k=1)\n","\n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 10,\n","                        max_single_channel_length = 200,\n","                        verbose = 0\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        precision, recall, f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","        \n","        # single\n","        seq2seq = Seq2Seq(alerts = alerts, \n","                        labels = labels,\n","                        X = X,\n","                        y = y, \n","                        latent_dim = 64, \n","                        batch_size = 32, \n","                        epochs = 8,\n","                        max_single_channel_length = 200,\n","                        verbose = 0,\n","                        multi_channel = False\n","                    )\n","        seq2seq.train()\n","        y_true, output = seq2seq.evaluation()\n","        s_precision, s_recall, s_f1 = eva_metrics5(y_true,output,stages = stages)\n","\n","\n","        csvFile = open(output_file,'a+',newline='')\n","        try:\n","            writer=csv.writer(csvFile)\n","            writer.writerow((input_file, len(X), length,\n","                             np.mean([len(xi) for xi in X]), seq2seq.max_encoder_seq_length, \n","                             output_length, 'seq2seq-hmm',\n","                             precision, s_precision,recall,s_recall, f1, s_f1))\n","        finally:\n","            csvFile.close()\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------- epoch 0 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 684\n","Max sequence length for outputs: 4\n","training spend time:0.05604758809010188\n","precison:  1.0\n","recall:  0.9655172413793104\n","f1:  0.9824561403508771\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 684\n","Max sequence length for outputs: 4\n","training spend time:0.06959164669116338\n","------------- epoch 0 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1834\n","Max sequence length for outputs: 4\n","training spend time:0.07634679992993673\n","precison:  0.7486910994764397\n","recall:  1.0\n","f1:  0.8562874251497006\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1834\n","Max sequence length for outputs: 4\n","training spend time:0.18462784498929977\n","precison:  0.5133333333333333\n","recall:  1.0\n","f1:  0.6784140969162996\n","------------- epoch 0 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3277\n","Max sequence length for outputs: 4\n","training spend time:0.10508553624153137\n","precison:  0.9382022471910112\n","recall:  0.5251572327044025\n","f1:  0.6733870967741935\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3277\n","Max sequence length for outputs: 4\n","training spend time:0.3449872745076815\n","precison:  0.5\n","recall:  1.0\n","f1:  0.6666666666666666\n","------------- epoch 0 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4771\n","Max sequence length for outputs: 4\n","training spend time:0.10949172496795655\n","precison:  0.9931972789115646\n","recall:  1.0\n","f1:  0.9965870307167235\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4771\n","Max sequence length for outputs: 4\n","training spend time:0.5980747961004576\n","------------- epoch 0 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6239\n","Max sequence length for outputs: 4\n","training spend time:0.12421148329973221\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6239\n","Max sequence length for outputs: 4\n","training spend time:0.8285825455188751\n","------------- epoch 1 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 667\n","Max sequence length for outputs: 4\n","training spend time:0.05501085917154948\n","precison:  1.0\n","recall:  0.9764309764309764\n","f1:  0.9880749574105622\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 667\n","Max sequence length for outputs: 4\n","training spend time:0.06443202555179596\n","precison:  0.48833333333333334\n","recall:  1.0\n","f1:  0.6562150055991042\n","------------- epoch 1 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1858\n","Max sequence length for outputs: 4\n","training spend time:0.07820401241381963\n","precison:  0.8068181818181818\n","recall:  1.0\n","f1:  0.8930817610062893\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1858\n","Max sequence length for outputs: 4\n","training spend time:0.18756129999955495\n","precison:  0.4716666666666667\n","recall:  1.0\n","f1:  0.6409966024915063\n","------------- epoch 1 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3291\n","Max sequence length for outputs: 4\n","training spend time:0.10618061751127243\n","precison:  0.9793103448275862\n","recall:  1.0\n","f1:  0.9895470383275261\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3291\n","Max sequence length for outputs: 4\n","training spend time:0.3804324945807457\n","precison:  0.5183333333333333\n","recall:  1.0\n","f1:  0.6827661909989022\n","------------- epoch 1 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4754\n","Max sequence length for outputs: 4\n","training spend time:0.11021276126305263\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4754\n","Max sequence length for outputs: 4\n","training spend time:0.5907319749395052\n","precison:  0.495\n","recall:  1.0\n","f1:  0.6622073578595317\n","------------- epoch 1 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6237\n","Max sequence length for outputs: 4\n","training spend time:0.12537547697623572\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6237\n","Max sequence length for outputs: 4\n","training spend time:0.862034540573756\n","precison:  0.5083333333333333\n","recall:  1.0\n","f1:  0.6740331491712707\n","------------- epoch 2 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 653\n","Max sequence length for outputs: 4\n","training spend time:0.05551947991053263\n","precison:  1.0\n","recall:  0.8566433566433567\n","f1:  0.9227871939736346\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 653\n","Max sequence length for outputs: 4\n","training spend time:0.06611395041147868\n","------------- epoch 2 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1802\n","Max sequence length for outputs: 4\n","training spend time:0.0773478842775027\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1802\n","Max sequence length for outputs: 4\n","training spend time:0.18040479779243468\n","------------- epoch 2 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3298\n","Max sequence length for outputs: 4\n","training spend time:0.1078420893351237\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3298\n","Max sequence length for outputs: 4\n","training spend time:0.34520181993643445\n","------------- epoch 2 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4781\n","Max sequence length for outputs: 4\n","training spend time:0.1128343003988266\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4781\n","Max sequence length for outputs: 4\n","training spend time:0.6145226573944091\n","precison:  0.495\n","recall:  1.0\n","f1:  0.6622073578595317\n","------------- epoch 2 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6281\n","Max sequence length for outputs: 4\n","training spend time:0.12975872000058492\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6281\n","Max sequence length for outputs: 4\n","training spend time:0.8666825048128763\n","------------- epoch 3 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 668\n","Max sequence length for outputs: 4\n","training spend time:0.05600452830394109\n","precison:  0.9822695035460993\n","recall:  0.9141914191419142\n","f1:  0.947008547008547\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 668\n","Max sequence length for outputs: 4\n","training spend time:0.0649676971634229\n","------------- epoch 3 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1846\n","Max sequence length for outputs: 4\n","training spend time:0.07914387911558152\n","precison:  0.8032345013477089\n","recall:  1.0\n","f1:  0.890881913303438\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1846\n","Max sequence length for outputs: 4\n","training spend time:0.19059071332216262\n","------------- epoch 3 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3315\n","Max sequence length for outputs: 4\n","training spend time:0.10874343772729238\n","precison:  0.7222222222222222\n","recall:  1.0\n","f1:  0.8387096774193548\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3315\n","Max sequence length for outputs: 4\n","training spend time:0.3885457394520442\n","precison:  0.5133333333333333\n","recall:  1.0\n","f1:  0.6784140969162996\n","------------- epoch 3 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4781\n","Max sequence length for outputs: 4\n","training spend time:0.11287283857663473\n","precison:  0.9815384615384616\n","recall:  1.0\n","f1:  0.9906832298136645\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4781\n","Max sequence length for outputs: 4\n","training spend time:0.6331360131502152\n","precison:  0.55\n","recall:  1.0\n","f1:  0.7096774193548387\n","------------- epoch 3 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6254\n","Max sequence length for outputs: 4\n","training spend time:0.127454727490743\n","precison:  1.0\n","recall:  0.267741935483871\n","f1:  0.4223918575063613\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6254\n","Max sequence length for outputs: 4\n","training spend time:0.8810714829961459\n","------------- epoch 4 n_steps :100 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 686\n","Max sequence length for outputs: 4\n","training spend time:0.05847614804903666\n","precison:  1.0\n","recall:  0.9391025641025641\n","f1:  0.968595041322314\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 686\n","Max sequence length for outputs: 4\n","training spend time:0.06796498546997706\n","precison:  0.5116666666666667\n","recall:  1.0\n","f1:  0.6769570011025359\n","------------- epoch 4 n_steps :500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1800\n","Max sequence length for outputs: 4\n","training spend time:0.08413603484630584\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 1800\n","Max sequence length for outputs: 4\n","training spend time:0.1777967439095179\n","------------- epoch 4 n_steps :1000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3314\n","Max sequence length for outputs: 4\n","training spend time:0.10907870789368947\n","precison:  0.8814589665653495\n","recall:  1.0\n","f1:  0.9369951534733442\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 3314\n","Max sequence length for outputs: 4\n","training spend time:0.37673874219258624\n","------------- epoch 4 n_steps :1500 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4785\n","Max sequence length for outputs: 4\n","training spend time:0.11319558491309484\n","precison:  1.0\n","recall:  1.0\n","f1:  1.0\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 4785\n","Max sequence length for outputs: 4\n","training spend time:0.63699615051349\n","------------- epoch 4 n_steps :2000 -----------\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6242\n","Max sequence length for outputs: 4\n","training spend time:0.12626695940891902\n","precison:  0.9965277777777778\n","recall:  1.0\n","f1:  0.9982608695652174\n","Number of samples: 3000\n","Number of unique input tokens: 18\n","Number of unique output tokens: 5\n","output tokens: ['eos', 'o', 's1', 's2', 'sos']\n","Max sequence length for inputs: 6242\n","Max sequence length for outputs: 4\n","training spend time:0.8123151873548825\n"],"name":"stdout"}]}]}